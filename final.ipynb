{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6fa96e-b5fc-4ca1-b55a-a149f7be5c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision.models import vgg16\n",
    "import glob\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b733abb4-b41e-429c-9d6b-33f6b1dd21c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join(os.path.abspath(\"..\"), \"../camera trap photos/PROJECT/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b92304-7ebd-44c8-81db-de5e72bdd4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribution: [Code from PyTorch docs](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html?highlight=transfer%20learning)\n",
    "\n",
    "IMAGE_LENGTH = 711\n",
    "IMAGE_WIDTH = 400\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((IMAGE_WIDTH, IMAGE_LENGTH)),     \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),            \n",
    "        ]\n",
    "    ),\n",
    "    \"valid\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((IMAGE_WIDTH, IMAGE_LENGTH)),                        \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),                        \n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\n",
    "    for x in [\"train\", \"valid\"]\n",
    "}\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=24, shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [\"train\", \"valid\"]\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
    "class_names = image_datasets[\"train\"].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9460f68d-5c46-4b3c-8634-b897ec4e8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, train_loader, valid_loader):\n",
    "    with torch.no_grad():\n",
    "        Z_train = torch.empty((0, 1024))\n",
    "        y_train = torch.empty((0))\n",
    "        Z_valid = torch.empty((0, 1024))\n",
    "        y_valid = torch.empty((0))\n",
    "        for X, y in train_loader:\n",
    "            Z_train = torch.cat((Z_train, model(X)), dim=0)\n",
    "            y_train = torch.cat((y_train, y))\n",
    "        for X, y in valid_loader:\n",
    "            Z_valid = torch.cat((Z_valid, model(X)), dim=0)\n",
    "            y_valid = torch.cat((y_valid, y))\n",
    "    return Z_train.detach(), y_train.detach(), Z_valid.detach(), y_valid.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc16eea-a556-4845-98c2-c26b8315949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet = models.densenet121(weights=\"DenseNet121_Weights.IMAGENET1K_V1\")\n",
    "densenet.classifier = nn.Identity()  # remove last \"classification\" layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47bfd04c-fa2d-4365-9c00-1e2a4a8293f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train, y_train, Z_valid, y_valid = get_features(\n",
    "    densenet, dataloaders[\"train\"], dataloaders[\"valid\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42eebb6e-b948-4fd5-a3e9-809f9047916e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=3000, C=10))\n",
    "pipe.fit(Z_train, y_train)\n",
    "pipe.score(Z_train.numpy(), y_train.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f80ba82-7d35-4181-af13-008b19ca7ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(Z_valid.numpy(), y_valid.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5f85eec-374a-4c28-8d45-b122137cb2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Predicted animals  Predicted nothing  Predicted people\n",
      "Actual animals                 67                  5                 0\n",
      "Actual nothing                 15                 18                 2\n",
      "Actual people                  33                 17                 3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = pipe.predict(Z_valid.numpy())\n",
    "cm = confusion_matrix(y_valid, y_pred, labels=[0, 1, 2])\n",
    "df_cm = pd.DataFrame(cm, \n",
    "                     index=[f'Actual {name}' for name in class_names],\n",
    "                     columns=[f'Predicted {name}' for name in class_names])\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3329e995-273a-4c63-b9c1-59fc6ac31734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attribution: [Code from PyTorch docs](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html?highlight=transfer%20learning)\n",
    "\n",
    "IMAGE_LENGTH = 711\n",
    "IMAGE_WIDTH = 400\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((IMAGE_WIDTH, IMAGE_LENGTH)),     \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),            \n",
    "        ]\n",
    "    ),\n",
    "    \"valid\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((IMAGE_WIDTH, IMAGE_LENGTH)),                        \n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),                        \n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\n",
    "    for x in [\"train\", \"valid\"]\n",
    "}\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x], batch_size=24, shuffle=True, num_workers=4\n",
    "    )\n",
    "    for x in [\"train\", \"valid\"]\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in [\"train\", \"valid\"]}\n",
    "class_names = image_datasets[\"train\"].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "709fd5ff-ef02-4259-a185-01584afd27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_train, y_train, Z_valid, y_valid = get_features(\n",
    "    densenet, dataloaders[\"train\"], dataloaders[\"valid\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "067ab40f-122c-4182-936d-f4f2d3eb9c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=3000, C=10))\n",
    "pipe.fit(Z_train, y_train)\n",
    "pipe.score(Z_train.numpy(), y_train.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "168fd2eb-e6b4-4b3a-8223-573b80b6498a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(Z_valid.numpy(), y_valid.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4b3d12-211b-4aac-b1f6-1c5ba71f27ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Predicted nothing  Predicted something\n",
      "Actual nothing                   14                   21\n",
      "Actual something                 15                  110\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = pipe.predict(Z_valid.numpy())\n",
    "cm = confusion_matrix(y_valid, y_pred, labels=[0, 1])\n",
    "df_cm = pd.DataFrame(cm, \n",
    "                     index=[f'Actual {name}' for name in class_names],\n",
    "                     columns=[f'Predicted {name}' for name in class_names])\n",
    "print(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "327e14f2-8998-4c83-b3c3-3820c964f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     nothing       0.48      0.40      0.44        35\n",
      "   something       0.84      0.88      0.86       125\n",
      "\n",
      "    accuracy                           0.78       160\n",
      "   macro avg       0.66      0.64      0.65       160\n",
      "weighted avg       0.76      0.78      0.77       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_valid, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c79f35c-213a-4e81-971d-4453df871638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['final_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(pipe, \"final_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f825daa4-7e33-455b-81f0-c30f61c1e1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nothing', 'something']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64141b2b-2998-4d7a-92b5-a08b931108c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:330] *",
   "language": "python",
   "name": "conda-env-330-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
